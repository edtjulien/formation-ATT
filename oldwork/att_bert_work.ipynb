{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     # only use GPU memory that we need, not allocate all the GPU memory\n",
    "#     tf.config.experimental.set_memory_growth(gpus[0], enable=True)\n",
    "\n",
    "# Set CPU as available physical device (for BERT)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  # Disable first GPU\n",
    "  tf.config.set_visible_devices(physical_devices[1:], 'GPU')\n",
    "  logical_devices = tf.config.list_logical_devices('GPU')\n",
    "  # Logical device was not created for first GPU\n",
    "  assert len(logical_devices) == len(physical_devices) - 1\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass\n",
    "\n",
    "#https://predictivehacks.com/?all-tips=how-to-get-bert-embeddings-with-tensorflow-hub\n",
    "#https://www.analyticsvidhya.com/blog/2021/09/performing-email-spam-detection-using-bert-in-python/\n",
    "#https://www.analyticsvidhya.com/blog/2020/10/simple-text-multi-classification-task-using-keras-bert/\n",
    "#https://medium.com/analytics-vidhya/understanding-bert-usage-31af2042be9e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='Latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target                                               text\n",
       "0       ham  Go until jurong point, crazy.. Available only ...\n",
       "1       ham                      Ok lar... Joking wif u oni...\n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       ham  U dun say so early hor... U c already then say...\n",
       "4       ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...     ...                                                ...\n",
       "5567   spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568    ham              Will Ì_ b going to esplanade fr home?\n",
       "5569    ham  Pity, * was in mood for that. So...any other s...\n",
       "5570    ham  The guy did some bitching but I acted like i'd...\n",
       "5571    ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[:,['v1','v2']]\n",
    "df.columns = ['target','text']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target_encoded'] = df['target'].map({'ham':0,'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xval, ytrain, yval = train_test_split(df['text'], df[\"target_encoded\"], test_size=0.2, stratify=df[\"target_encoded\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:16:02.405062: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# downloading preprocessing files and model\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text  # Imports TF ops for preprocessing\n",
    "\n",
    "bert_preprocessor = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
    "bert_encoder = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = tf.keras.layers.Input(shape = (), dtype = tf.string, name = 'Inputs')\n",
    "preprocessed_text = bert_preprocessor(text_input)\n",
    "embeed = bert_encoder(preprocessed_text)\n",
    "layer1 = tf.keras.layers.Dense(64, activation='relu')(embeed['pooled_output']),\n",
    "layer2 = tf.keras.layers.Dropout(0.1)(layer1)\n",
    "layer3 = tf.keras.layers.Dense(32, activation='relu')(layer2)\n",
    "layer4 = tf.keras.layers.Dropout(0.1)(layer3)\n",
    "outputs = tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'Dense')(layer4)\n",
    "\n",
    "# creating final model\n",
    "model = tf.keras.Model(inputs = [text_input], outputs = [outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer ='adam',\n",
    "               loss = 'binary_crossentropy',\n",
    "               metrics = [f1,tf.keras.metrics.BinaryAccuracy(name = 'accuracy'),\n",
    "                            tf.keras.metrics.Precision(name = 'precision'),\n",
    "                            tf.keras.metrics.Recall(name = 'recall')\n",
    "           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "140/140 [==============================] - 332s 2s/step - loss: 0.4151 - f1: 0.0018 - accuracy: 0.8599 - precision: 0.1714 - recall: 0.0100\n",
      "Epoch 2/5\n",
      " 12/140 [=>............................] - ETA: 4:31 - loss: 0.3985 - f1: 0.0000e+00 - accuracy: 0.8698 - precision: 0.0000e+00 - recall: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(xtrain, ytrain, epochs \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, callbacks\u001b[39m=\u001b[39;49m[tensorboard_callback])\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(xtrain, ytrain, epochs = 5, verbose=True, callbacks=[tensorboard_callback])\n",
    "\n",
    "# with tf.device('/cpu:0'): ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 75s 2s/step - loss: 0.1814 - f1: 0.5857 - accuracy: 0.9291 - precision: 0.9268 - recall: 0.5101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18141554296016693,\n",
       " 0.5857062935829163,\n",
       " 0.9291479587554932,\n",
       " 0.9268292784690857,\n",
       " 0.5100671052932739]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xval,yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.save('history1.npy',history.history)\n",
    "history1=np.load('history1.npy', allow_pickle='TRUE').item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 16:28:05.600228: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# downloading preprocessing files and model\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text  # Imports TF ops for preprocessing\n",
    "\n",
    "# Define the model\n",
    "BERT_MODEL = \"https://tfhub.dev/google/experts/bert/wiki_books/2\"\n",
    "# Choose the preprocessing that must match the model\n",
    "PREPROCESS_MODEL = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    "\n",
    "preprocess = hub.load(PREPROCESS_MODEL)\n",
    "bert = hub.load(BERT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Inputs (InputLayer)            [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'input_mask': (Non  0           ['Inputs[0][0]']                 \n",
      "                                e, 128),                                                          \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     {'default': (None,   109482241   ['keras_layer[0][0]',            \n",
      "                                768),                             'keras_layer[0][1]',            \n",
      "                                 'encoder_outputs':               'keras_layer[0][2]']            \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 768),                                                       \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768)}                                                \n",
      "                                                                                                  \n",
      " Dropout (Dropout)              (None, 768)          0           ['keras_layer_1[0][13]']         \n",
      "                                                                                                  \n",
      " Dense (Dense)                  (None, 1)            769         ['Dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,010\n",
      "Trainable params: 769\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_emb(input_text):\n",
    "  input_text_lst = [input_text]\n",
    "  inputs = preprocess(input_text_lst)\n",
    "  outputs = bert(inputs)\n",
    "  return np.array((outputs['pooled_output']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.6730153   0.16980024  0.0517062   0.49646884  0.5704644   0.3031674\n",
      "  -0.07520075 -0.9905823   0.9418097   0.3562777  -0.9015574  -0.9523854\n",
      "  -0.2330077   0.3878442  -0.39498916 -0.21855661  0.23766173  0.987274\n",
      "  -0.10497741  0.7786637  -0.29289722  0.71026987  0.3471179  -0.5728613\n",
      "   0.9419618   0.37325022 -0.5141686   0.85436046  0.20006509 -0.31995782\n",
      "   0.1932226  -0.26115093 -0.28056735  0.17820473 -0.01893848  0.53536505\n",
      "  -0.60382813  0.7433764  -0.9028417   0.05744893  0.47359225  0.2269099\n",
      "   0.22758965 -0.18882677  0.74394166 -0.16068767  0.27666396  0.657109\n",
      "   0.60050666 -0.38498506  0.02086009  0.905419    0.61438924 -0.64821756\n",
      "   0.20391536 -0.65669554  0.91290754  0.05876156 -0.43066576 -0.85168594\n",
      "  -0.6492433   0.5278645  -0.72371054 -0.559621   -0.08929721 -0.12537009\n",
      "   0.2024772   0.80765194  0.82415664  0.40183684 -0.8625045   0.7244723\n",
      "  -0.7604728   0.8433044  -0.03106003  0.8740302  -0.64227927 -0.62824893\n",
      "   0.89689255  0.37437546  0.72798795 -0.8155506  -0.05495691 -0.5582536\n",
      "   0.17123093  0.375988   -0.09196341  0.61146003 -0.32378998  0.24750702\n",
      "  -0.39643523  0.47826514  0.22620444  0.5662105   0.3644377   0.55285513\n",
      "   0.07569138 -0.26738036 -0.19353257  0.538845   -0.4358399   0.8440714\n",
      "   0.06419555  0.7888292   0.24071135  0.16170046  0.35026     0.12345807\n",
      "  -0.15099025  0.5304659  -0.6915039   0.01775793 -0.10740218 -0.09984687\n",
      "  -0.10633851 -0.97941136 -0.57916856  0.84562016  0.5488423  -0.740293\n",
      "  -0.15224762 -0.24689147  0.4736893  -0.7449617  -0.19403245 -0.81937593\n",
      "   0.8135732  -0.07386317  0.9303228   0.5500026  -0.47200024 -0.5221945\n",
      "   0.389711   -0.7788221   0.3052984   0.5659473   0.5028541   0.21413647\n",
      "   0.28231767  0.00213279  0.46967372  0.8029636   0.6421913   0.34157538\n",
      "   0.6024075   0.6190624   0.04286201 -0.00563332 -0.07454804 -0.2752616\n",
      "  -0.23691851 -0.922326    0.11994932  0.06925798 -0.6147321   0.60229105\n",
      "   0.8373852  -0.945362   -0.49215898  0.7440282  -0.9053105  -0.56981796\n",
      "   0.7955274  -0.02732428 -0.12994318 -0.6657166  -0.6921781  -0.46355376\n",
      "  -0.03009804  0.89109015 -0.35241875  0.16808988 -0.32805082  0.64062995\n",
      "   0.51764643 -0.8302863   0.5692962   0.06284204  0.11062633  0.18563828\n",
      "   0.8177807   0.5670765  -0.48993996 -0.16224597  0.28398222 -0.5458948\n",
      "   0.1623815   0.23734406  0.287059    0.6928125   0.89724916 -0.8863994\n",
      "   0.7547327  -0.07854553 -0.20303667  0.2871877  -0.67136043  0.7795405\n",
      "  -0.8561141   0.787632   -0.5752466   0.08114406 -0.7690167  -0.40632844\n",
      "  -0.39352605 -0.7305742   0.6629676  -0.27778357 -0.4247319   0.80206776\n",
      "  -0.3801916  -0.20844123  0.8076505  -0.11806223 -0.84555316  0.82366765\n",
      "   0.25363064  0.2483038   0.98534805  0.55731887 -0.1030377   0.45851955\n",
      "  -0.7318512  -0.35476944  0.01970113 -0.1340794  -0.15646635 -0.2822492\n",
      "  -0.31432328  0.56251585 -0.21942408 -0.5252217   0.03258969 -0.6247879\n",
      "   0.20575483  0.42673668 -0.41592693  0.16229081 -0.27176356 -0.5130686\n",
      "   0.3742495  -0.3634789   0.8409966   0.49413222  0.54547817 -0.4223928\n",
      "   0.14571472 -0.5276971  -0.6126941   0.18589135 -0.16221665  0.8145801\n",
      "  -0.33885714 -0.89937353  0.7806547   0.65318775 -0.2595744   0.504409\n",
      "  -0.9235957  -0.01749942 -0.6087771  -0.8921051  -0.08380449 -0.11169611\n",
      "  -0.5786916  -0.65260947  0.8746493   0.14138946 -0.9241845  -0.08878865\n",
      "   0.87536144  0.4842671   0.7587084   0.6551765   0.49476954  0.40601233\n",
      "   0.5294342  -0.6608214   0.03019154  0.48523915  0.40156263  0.73403907\n",
      "   0.50444037 -0.6267066   0.5953874  -0.8670578  -0.57228714  0.6443674\n",
      "   0.51226     0.7378189  -0.02163971 -0.35654587 -0.09477025  0.48916322\n",
      "  -0.5514376  -0.77929413 -0.1045815   0.88722056  0.3994379  -0.30271688\n",
      "  -0.766229    0.12585016 -0.66357946  0.5500631  -0.16958223  0.7815472\n",
      "  -0.36447066 -0.669389   -0.47096357  0.2927521   0.6563182   0.1346569\n",
      "   0.28758058 -0.62539214  0.87529105 -0.38267738 -0.12565273  0.3869032\n",
      "   0.78740835 -0.6661768   0.75148386 -0.72885436  0.27228796 -0.88382494\n",
      "   0.6330144   0.07850853  0.39277196  0.4094477   0.2536319  -0.8368335\n",
      "   0.4998583  -0.5295343   0.08220072  0.06255653 -0.106932    0.85786283\n",
      "   0.99999976 -0.5499176  -0.15713376 -0.07119193 -0.24773797  0.01911598\n",
      "   0.9348303   0.75491595 -0.5755785  -0.45276418  0.8093115   0.33295897\n",
      "  -0.40306157 -0.68117404  0.8270849  -0.69980055  0.49136513 -0.7383859\n",
      "   0.75470036  0.7707317  -0.73782855  0.72850806  0.5399151  -0.63593227\n",
      "  -0.7982662   0.12448943 -0.8649494   0.24158622  0.5898931  -0.20981225\n",
      "   0.94171286  0.0708376  -0.08947808 -0.5452176   0.47614664 -0.5781414\n",
      "   0.151646   -0.41073346 -0.5285453  -0.38013345 -0.08976156 -0.29226655\n",
      "   0.1443173   0.00819744 -0.7391431   0.35368115  0.69359046 -0.57341313\n",
      "  -0.73867667  0.98019487  0.38535285 -0.5920353  -0.05208801 -0.5520978\n",
      "  -0.89493513  0.49341902  0.9851933   0.64740473 -0.3731341  -0.12237769\n",
      "  -0.61914456  0.15844487 -0.64167416  0.7527379   0.14867081  0.01175603\n",
      "   0.28405342  0.4852624  -0.2365351   0.11986911 -0.16539842  0.5481172\n",
      "   0.91350687 -0.620665   -0.15546046 -0.6326845   0.6591587   0.28186536\n",
      "  -0.66260016  0.76411927 -0.59283704  0.20650996  0.5660786  -0.9457113\n",
      "  -0.6824521  -0.23711453 -0.2980226   0.09466171  0.36883363 -0.02752275\n",
      "   0.7832089   0.5066127  -0.9283949  -0.31838396 -0.26733238  0.32098192\n",
      "   0.9389272   0.7737086  -0.03877098 -0.3929291   0.52113545 -0.19330229\n",
      "   0.97269696 -0.6800308   0.19863509 -0.37123328  0.1709218   0.7958924\n",
      "  -0.40229693 -0.08855497  0.558036   -0.91002005  0.01199927 -0.5721034\n",
      "   0.16739102  0.23937984 -0.80892384 -0.55062693  0.29898342 -0.09058786\n",
      "  -0.39613235  0.80744725  0.24588718  0.13286805  0.51744384 -0.39918867\n",
      "  -0.83425295  0.8506315   0.59761685 -0.92741513  0.18803194  0.7918331\n",
      "   0.6106663  -0.9665809   0.02010602  0.65715456  0.98853606  0.13358109\n",
      "   0.76995194 -0.78050655 -0.37292212  0.518749    0.9603823  -0.44194776\n",
      "  -0.21950626  0.08696627  0.5047914   0.74572194  0.51064754 -0.5372885\n",
      "   0.24410251 -0.76932174  0.54249114 -0.08349405  0.02219837 -0.09383622\n",
      "  -0.5858806  -0.5833687   0.13884382 -0.50816464 -0.86722016 -0.31960467\n",
      "  -0.48759198 -0.05716949 -0.37544245  0.91469413  0.05460807  0.40769172\n",
      "   0.14873545  0.9647012   0.5442969  -0.58452964 -0.81948066  0.49447098\n",
      "  -0.35199523 -0.38321123 -0.9260689  -0.00968497 -0.0561844   0.1938925\n",
      "  -0.6156282  -0.04752297 -0.08293811  0.26774192 -0.43868932 -0.03512565\n",
      "  -0.8176187  -0.2935601   0.86454993 -0.51754355 -0.1353753   0.9414274\n",
      "  -0.05341237  0.5255254   0.22197786  0.5930039  -0.8672603   0.5197631\n",
      "  -0.88549006  0.03452136  0.10718377 -0.57697195 -0.73083913  0.65018296\n",
      "  -0.76268697  0.0433565   0.86983246  0.10923959  0.20219384 -0.5935673\n",
      "  -0.30323693 -0.86427176  0.9534917  -0.15510614  0.50590223 -0.46319878\n",
      "   0.9687086  -0.1577252  -0.7100318   0.66678816  0.66547614 -0.7393586\n",
      "   0.29440144  0.62558675 -0.44006613  0.5028734   0.77952576 -0.3131735\n",
      "   0.55271506  0.9259221  -0.59863627  0.39058945  0.3582048  -0.27209315\n",
      "  -0.27959996 -0.794158    0.6412087  -0.7912216   0.42936674  0.9671391\n",
      "   0.6318796   0.6786745  -0.73232365  0.01204835 -0.82326746  0.31623572\n",
      "  -0.6007269  -0.36387068  0.40656635 -0.08021259  0.841534   -0.6551731\n",
      "  -0.6723677  -0.1648896  -0.75488293 -0.24140717  0.8234992  -0.74223274\n",
      "  -0.40374017 -0.5995354  -0.10236111 -0.35924473  0.29011214  0.21108712\n",
      "   0.341692   -0.1476917  -0.19525796  0.07727031  0.2335215   0.6468684\n",
      "  -0.25488538 -0.8195485  -0.93099487  0.2249518  -0.04465725  0.20996876\n",
      "  -0.6659182   0.41898948 -0.74667645  0.47991988 -0.60365635  0.7407341\n",
      "   0.19834761 -0.08305444 -0.7565202   0.62395877 -0.42447188 -0.93718666\n",
      "  -0.8467138   0.7138213  -0.6960871   0.24486549  0.41653758 -0.9619109\n",
      "  -0.27504086  0.5105832  -0.8221213   0.31092623  0.88213223  0.5005718\n",
      "  -0.22526282  0.4990323  -0.04813781  0.5023264   0.917301   -0.53394216\n",
      "  -0.94735056  0.7834529   0.69839394  0.4566284   0.7211284   0.47076106\n",
      "  -0.70173794 -0.4698251  -0.2884745  -0.45235908 -0.02976375 -0.2961778\n",
      "  -0.48036203 -0.80544996 -0.31315583 -0.09518199  0.26785672 -0.19250703\n",
      "   0.6097834   0.34632245  0.417503    0.73657584  0.13470128 -0.06298575\n",
      "  -0.9176084  -0.7998057   0.805481    0.62469137  0.40255013 -0.6525629\n",
      "   0.09344216 -0.8283299   0.65734845 -0.9341302  -0.14811741 -0.08675408\n",
      "  -0.05359743 -0.33995676 -0.8680653   0.07849824  0.6589941  -0.253262\n",
      "   0.4005554  -0.38143438  0.7112426   0.42135975 -0.3016339  -0.629905\n",
      "   0.47449094  0.42017084  0.5001905   0.0120371  -0.27605426  0.82100374\n",
      "   0.5168531  -0.8900634   0.5084492  -0.36855456 -0.42355     0.18319373\n",
      "  -0.58750147  0.3174738  -0.608698    0.73243535 -0.15229258 -0.3560406\n",
      "  -0.9717891   0.9758784   0.6555427   0.7095163   0.5594815   0.90805924\n",
      "   0.95690376  0.18588325  0.28055918  0.1517125  -0.03090432  0.06904019\n",
      "   0.3109744  -0.47681433  0.8704893  -0.0872042  -0.6993945  -0.7564398\n",
      "   0.06625845 -0.26507375  0.5123508  -0.86400265  0.7378015   0.02031249\n",
      "  -0.14361782 -0.31732905 -0.46801844 -0.58016604  0.48166615 -0.8687632\n",
      "   0.7134541   0.4255442   0.04459183  0.4801401   0.79735845  0.7893004\n",
      "  -0.58762443  0.5699222  -0.78559774  0.54470146  0.31301945  0.14564501\n",
      "   0.9632195   0.6026403  -0.43342364  0.8212961   0.3693763   0.26091534\n",
      "  -0.4036037  -0.0660583   0.94566876  0.64764506 -0.81161875  0.16137624\n",
      "  -0.82644725 -0.599497   -0.02595755  0.27349585 -0.8450599  -0.39394504]]\n"
     ]
    }
   ],
   "source": [
    "print(text_to_emb('This is a sample sentence'))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fe655022548373991488107ee87292a5acc65b103412eeef527175bfc11a68a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
